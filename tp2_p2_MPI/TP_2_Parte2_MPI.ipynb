{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc7c0Vvas0+ZHGFYM1Fdmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lx-jdar/progra-concurrente/blob/development/tp2_p2_MPI/TP_2_Parte2_MPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programación Concurrente - TP2 - Parte 2\n",
        "\n",
        "Para este ejercicio se ha optado por aplicar el tema teórico **MPI** (Message Passing Interface). La finalidad del ejercicio es ampliar el conocimiento sobras la manera que posee Python para implementar la comunicación entre distintos procesos con el uso de una librería denominada **MPI4py** [1]. Para más información puede consultar la última revisión en [2]."
      ],
      "metadata": {
        "id": "0ZNqmIsKoJk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2.1. Ejercicio - Hola Mundo con MPI"
      ],
      "metadata": {
        "id": "S97WIXzfoN0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Preguntas del ejercicio\n",
        "\n",
        "Ejecute este ejemplo para $4$ o más instancias y responda:\n",
        "\n",
        "a) ¿Qué función realiza la instancia maestra? ¿Qué función realizan las instancias esclavas?\n",
        "\n",
        "La instancia maestra en el programa crea aleatoriamente tiempo a consumir en un vector de enteros. Una vez creado los tiempos distribuye esos valores a las distintas esclavas. Las instancias esclavas toman los valores procesandolo en pantalla y una vez terminado dan aviso que culminaron. Los procesos maestros van derivando mas tarea a medida que los esclavos van terminando y dando aviso de sus tareas a los maestros.\n",
        "Una vez terminadas todas las tareas, se cierra el ciclo de ejecución del programa.\n",
        "\n",
        "b) ¿Cuántas de esas instancias ejecuta la función `main()`, `initWork()` y `doWork()`?\n",
        "\n",
        "En main() se estaría conteniendo a todas las instancias, tanto el maestro como los esclavos. initWork() es en donde la funcion maestra distribuye las tareas y solo se estaría ejecutando una instancia.\n",
        "Por el contrario, en doWork se ejecutan todas las instancias esclavas que van recibiendo los parámetros y van procesando la información.\n",
        "\n",
        "c) ¿Cómo se diferencian los mensajes de trabajo o de finalización?\n",
        "\n",
        "La instancia maestra informa por medio de tag=WORK_FLAG a los procesos esclavos para indicar que tiene pendiente horas a procesar. Una vez liquidado todas las posiciones del array provistos para las instancias, se envía un parametro tag=END_WORK_FLAG, que indica que a culminado el procesamiento de todas las posiciones por parte del proceso maestro.\n",
        "\n",
        "d) ¿Cómo implementaría la función BLAS `axpy()` con este patrón?¿Sería eficiente? *Tips*: Pide solo el planteo, no la implementación.\n",
        "\n",
        "Se debería correr a principio del programa la seccion secuencial y luego con -np $NRO realizar la parte de paralelismo con n procesos y ver los resultados de cada caso. La eficiencia dependerá de la cantidad de procesos y el hardware disponible para los procesos.\n",
        "\n",
        "e) ¿Qué sucede cuando solo ejecuta con una sola instancia?\n",
        "\n",
        "No se ejecuta ya que hay una restricción (numProcesses-1)*4 que determina que si no se puede definir esclavos, la instancia del programa no se ejecute.\n",
        "\n",
        "f) *Punto opcional*: El código que ejecutan las instancias esclavas, tienen un error en su lógica. ¿Cómo se podría solucionar?"
      ],
      "metadata": {
        "id": "ParsPpiRoRJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1.2. Armado del ambiente\n",
        "\n",
        "Es en donde se instalar, por única vez, el módulo MPI4py de Python en el cuaderno."
      ],
      "metadata": {
        "id": "FdbLmib4oVHP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WjRl1SRLnt8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41eafb9-1c9f-4468-c981-56178f1767c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp310-cp310-linux_x86_64.whl size=2746523 sha256=624a2a639c3b35c743e63b4cab41318274cd2b563348efe981132d31e49182da\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/2b/7f/c852523089e9182b45fca50ff56f49a51eeb6284fd25a66713\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.5\n"
          ]
        }
      ],
      "source": [
        "! pip install mpi4py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Código del programa en Lenguaje Python"
      ],
      "metadata": {
        "id": "m_DQwXzjoatu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Ejercicio2.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# --------------------------------------------\n",
        "# Formulario\n",
        "Max_tiempo_sleep =   1#@param {type: \"slider\", min: 1, max: 10}\n",
        "Min_tiempo_sleep =   0#@param {type: \"slider\", min: 0, max: 10}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Constantes de comunicacion\n",
        "WORK_FLAG = 1\n",
        "END_WORK_FLAG = 2\n",
        "# --------------------------------------------\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD # Instanciamos el tipo de comunicador a utilizar.\n",
        "    id = comm.Get_rank()  # Obtenemos el id como atributo del proceso que se ejecuta.\n",
        "\n",
        "    # Utilizamos el 0 para definir al procesos Maestro, cualquier otro id sera un esclavo.\n",
        "    if (id == 0) :\n",
        "        init() # Llamamos funcion init para eventos que requeriremos inicialmente solo 1 vez.\n",
        "        numProcesses = comm.Get_size()  # Obtenemos el numero de procesos totales ejecutados.\n",
        "        numTasks = (numProcesses-1)*4 # Se setea el numero de tareas.\n",
        "        workTimes = generateTasks(numTasks) # Se generan las tareas, en este caso seran\n",
        "        print(\"El jefe crea {} horas de descanso de sus empleados:\".format(workTimes.size), flush=True)\n",
        "        print(workTimes, flush=True)\n",
        "        initWork(comm, workTimes, numProcesses)\n",
        "    else:\n",
        "        doWork(comm)\n",
        "\n",
        "def generateTasks(numTasks):\n",
        "    #TODO: Cambiar la semilla del random para que se generen efectivamente diferentes numeros.\n",
        "    np.random.seed(1000)\n",
        "    return np.random.randint(low=Min_tiempo_sleep, high=Max_tiempo_sleep, size=numTasks)\n",
        "\n",
        "def init():\n",
        "  print()\n",
        "  print(\"Version MPI4py utilizada: {}\".format(MPI.Get_version()), flush=True)\n",
        "  print()\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print( \"Sistema de trabajo Suizo:\", flush=True)\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print()\n",
        "\n",
        "def initWork(comm, workTimes, numProcesses):\n",
        "    totalWork = workTimes.size\n",
        "    workcount = 0\n",
        "    recvcount = 0\n",
        "\n",
        "    print(\"Jefe enviando las tareas iniciales:\", flush=True)\n",
        "    for id in range(1, numProcesses):\n",
        "        if workcount < totalWork:\n",
        "            work=workTimes[workcount]\n",
        "            comm.send(work, dest=id, tag=WORK_FLAG) # Envia mensaje de iniciar trabajo con el dato correspondiente del array.\n",
        "            workcount += 1\n",
        "            print(\"Jefe envia trabajo y {} hs de descanso al empleado {}.\".format(work, id), flush=True)\n",
        "    print( \"------------------------------------\", flush=True)\n",
        "\n",
        "    # Mientras haya trabajo, se recibe el resultado de los empleados y se sigue enviando MAS trabajo.\n",
        "    while (workcount < totalWork) :\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat) # Recivimos resultados de los empleados.\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source() # Obtenemos el identificador del empleado.\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "        #send next work\n",
        "        work=workTimes[workcount]\n",
        "        comm.send(work, dest=workerId, tag=WORK_FLAG)\n",
        "        workcount += 1\n",
        "        print(\"Jefe envia nuevo trabajo y {} hs de descanso al empleado {}.\".format(work, workerId), flush=True)\n",
        "\n",
        "    while (recvcount < totalWork):\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat)\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source()\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "\n",
        "    for id in range(1, numProcesses):\n",
        "        comm.send(0, dest=id, tag=END_WORK_FLAG)\n",
        "\n",
        "\n",
        "def doWork(comm):\n",
        "    while(True):\n",
        "        stat = MPI.Status() # Obtiene el estado actual del empleado.\n",
        "        waitTime = comm.recv(source=0, tag=MPI.ANY_TAG, status=stat) # Obtiene lo enviado por el Jefe.\n",
        "        print(\"Soy el empleado con id {}, toca descanzo por {} hs.\".format(comm.Get_rank(), waitTime), flush=True)\n",
        "\n",
        "        if (stat.Get_tag() == END_WORK_FLAG):\n",
        "            print(\"Marca tarjeta el empleado {}.\".format(comm.Get_rank()), flush=True)\n",
        "            return\n",
        "        time.sleep(waitTime)\n",
        "        comm.send(waitTime, dest=0)\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "qFYv9q36oel8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d8d3b1-241a-4bb0-d3c8-c54266ddd979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Ejercicio2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 Ejecución del programa"
      ],
      "metadata": {
        "id": "nMwKcgA4onc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "#@title Parámetros de ejecución { vertical-output: true }\n",
        "NRO =   1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "! mpirun --oversubscribe --allow-run-as-root -np $NRO python Ejercicio2.py"
      ],
      "metadata": {
        "id": "cjZbcAUCoqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85b8b00-1e66-44e8-f000-856e6c205285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Version MPI4py utilizada: (3, 1)\n",
            "\n",
            "------------------------------------\n",
            "Sistema de trabajo Suizo:\n",
            "------------------------------------\n",
            "\n",
            "El jefe crea 0 horas de descanso de sus empleados:\n",
            "[]\n",
            "Jefe enviando las tareas iniciales:\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3.1 Ejercicio Contar palabras"
      ],
      "metadata": {
        "id": "UpK615qPo5si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollar un programa que permita obtener el valor máximo de un conjunto dado de forma distribuida.\n",
        "\n",
        "Las condiciones a tener en cuenta son:\n",
        "\n",
        "\n",
        "*   Debe trabajar con al menos, 4 procesos.\n",
        "*   El resultado final debe ser informado en cada proceso.\n",
        "*   Implementar comunicación por Buffer\n",
        "\n"
      ],
      "metadata": {
        "id": "9fRZdyduo86F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1.1 Preparación"
      ],
      "metadata": {
        "id": "Tg89H0mGo_vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_tp4.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "\n",
        "def main():\n",
        "  comm = MPI.COMM_WORLD\n",
        "  numProcesses = comm.Get_size() # numero de procesamientos\n",
        "  rank = comm.Get_rank()\n",
        "\n",
        "  count = 5\n",
        "  sendbuf = None\n",
        "\n",
        "  if rank == 0:\n",
        "    print(\"nro de procesos : {}\".format(numProcesses), flush=True)\n",
        "    sendbuf = np.random.randn(numProcesses, count)\n",
        "    print()\n",
        "  else:\n",
        "    sendbuf = None\n",
        "\n",
        "  smallerPart = np.empty(count, dtype='float')  # allocate space for result on each process\n",
        "  comm.Scatter(sendbuf, smallerPart, root=0)\n",
        "  max = comm.reduce(smallerPart.max(), op=MPI.MAX)\n",
        "\n",
        "  print(\"Rank {} has data: {}\".format(rank+1, smallerPart), flush=True)\n",
        "\n",
        "  if rank == 0:\n",
        "    print(\"\\nMaster {} of {} has original array after Scatter: \\n{}\\n\"\\\n",
        "    .format(rank+1, numProcesses, sendbuf), flush=True)\n",
        "    data = { 'info': max }\n",
        "  else:\n",
        "    data = {}\n",
        "\n",
        "  #initiate and complete the broadcast\n",
        "  data = comm.bcast(data, root=0)\n",
        "\n",
        "  print(\"Rank {} got max value: {} \".format(rank+1, data['info']), flush=True)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "yRk5xLcTpFDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55af3c9-c343-474d-8c7f-20125e941e89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_tp4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "# Formulario\n",
        "NRO =   5#@param {type: \"slider\", min: 4, max: 10}\n",
        "# --------------------------------------------\n",
        "\n",
        "! mpirun --oversubscribe --allow-run-as-root -np $NRO python mpi_tp4.py"
      ],
      "metadata": {
        "id": "ErzxJ1hnpIY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28249be9-f053-455c-cdbe-c21fffc62903"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nro de procesos : 5\n",
            "\n",
            "Rank 5 has data: [-0.47864939 -1.38943525 -0.76752844 -1.28487341  0.02915897]\n",
            "Rank 2 has data: [ 1.42185048  0.28112614 -0.5163519   0.32307783  2.05472753]\n",
            "Rank 4 has data: [-1.54921043 -0.49624981  1.43420213  0.3276727   0.55060586]\n",
            "Rank 3 has data: [ 0.48342971 -0.94074541  0.30238038 -2.30662505  1.1107557 ]\n",
            "Rank 1 has data: [0.95926544 1.91702087 0.3194928  0.90779229 0.87356754]\n",
            "\n",
            "Master 1 of 5 has original array after Scatter: \n",
            "[[ 0.95926544  1.91702087  0.3194928   0.90779229  0.87356754]\n",
            " [ 1.42185048  0.28112614 -0.5163519   0.32307783  2.05472753]\n",
            " [ 0.48342971 -0.94074541  0.30238038 -2.30662505  1.1107557 ]\n",
            " [-1.54921043 -0.49624981  1.43420213  0.3276727   0.55060586]\n",
            " [-0.47864939 -1.38943525 -0.76752844 -1.28487341  0.02915897]]\n",
            "\n",
            "Rank 1 got max value: 2.054727526578737 \n",
            "Rank 3 got max value: 2.054727526578737 \n",
            "Rank 2 got max value: 2.054727526578737 \n",
            "Rank 5 got max value: 2.054727526578737 \n",
            "Rank 4 got max value: 2.054727526578737 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Bibliografía\n",
        "\n",
        "[1] MPI4py: https://mpi4py.readthedocs.io/en/stable/\n",
        "\n",
        "[2] La versión oficial de MPI (Versión 4): https://www.mpi-forum.org/docs/mpi-4.0/mpi40-report.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "HHw4OWzspLk0"
      }
    }
  ]
}